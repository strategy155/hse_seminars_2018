{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Fundamentals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suggested readings: \n",
    "1. Bishop. p38-48\n",
    "1. Shapire. Boosting: Foundation and Algorithms. p 23-43"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outline\n",
    "1. Task formulation\n",
    "1. Loss function\n",
    "1. Empirical Risk minimization\n",
    "1. No free lunch Theorem\n",
    "1. Generalization bounds\n",
    "1. Complexity of hypothesis space. VC dimention. Rademacher complexity\n",
    "1. Bias Variance decomposition\n",
    "1. Overfitting and Regularization\n",
    "1. Quality Metrics\n",
    "1. Validation: Leave One Out, Cross-Validation, Hold Out\n",
    "1. Usual pipeline for model training\n",
    "1. Optimal Bayesian classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Task Formulation\n",
    "\n",
    "Here we will consider only classification or regression tasks.\n",
    "\n",
    "Given dataset $\\{ (x_i, y_i) \\}_{i=1}^N $ of i.i.d. objects\n",
    "\n",
    "Or, equvalently given:  \n",
    "$X \\in R^{Nxd}$ - feature matrix, where $d$ is dimension of feature space and $N$ - number of objects.  \n",
    "$Y \\in R^{N}$ - target vector\n",
    "\n",
    "For classification $Y \\in \\{0,1, ... C-1\\}^N$, where $C$ is a number of classes \n",
    "\n",
    "We want to find such algorithm $h \\in H$ that \"assigns for each object the right target value\".\n",
    "\n",
    "Classification\n",
    "<img src=\"images/classification.png\" style=\"height:300px\">\n",
    "\n",
    "Regression\n",
    "<img src=\"images/regression.png\" style=\"height:300px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Loss function\n",
    "\n",
    "$Loss: Y x Y -> R $ - loss function, that evaluates how bad our prediction for particular object are.\n",
    "\n",
    "Some loss functions:\n",
    "* $Loss(\\hat y, y) = (\\hat y - y)^2$\n",
    "* $Loss(\\hat y, y) = |\\hat y - y|$\n",
    "* $Loss(\\hat y, y) = \\frac {|\\hat y - y|} {y}$\n",
    "* $Loss(\\hat y, y) = I[\\hat y \\neq y]$\n",
    "\n",
    "\n",
    "For binary classification with $y \\in {-1,1}$ a variable $z = yh(x)$ is called margin. Positive margin corresponds to successful classification, negative margin corresponds to error. $|yh(x)|$ is a distance to decision boundary, which can be interpreted as confidence in classification of the object.     \n",
    "<img src=\"images/margin1.png\" style=\"height:300px\">\n",
    "\n",
    "Loss functions also can be determined in terms of margin:\n",
    "* $Loss(\\hat y, y) = max(0, 1 - yf(x))$ Hinge loss\n",
    "* $Loss(\\hat y, y) = e^(-yh(x))$ AdaBoost loss\n",
    "* $Loss(\\hat y, y) = \\log(1 + e^(-yh(x)))$ Logistic loss\n",
    "* $Loss(\\hat y, y) = I[yh(x) < 0]$ Classification error \n",
    "\n",
    "<img src=\"images/margin_loss.png\" style=\"height:300px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empirical Risk Minimization\n",
    "\n",
    "In general, we want to optimize Expected Risk:  \n",
    "$R = E [ Loss(x, y)] = \\int_{-\\infty}^{\\infty}Loss(x, y)dP(x,y) = Pr_{(x_i, y_i) ~ D} [Loss(x_i, y_i)] $\n",
    "\n",
    "But since we don't now the joint distibution $P(x,y)$, we can only deal with Empirical Risk (Loss functional):  \n",
    "$\\hat R = \\sum_{i=1}^{N}Loss(x_i, y_i) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalization bounds\n",
    "\n",
    "Hoeffding’s inequality:\n",
    "Let $x_1$,..., $x_m$ be independent random variables such that {x_i \\in [0,1]}.\n",
    "Denote their average value by $A_m = \\frac 1 m \\sum_i^m x_i$\n",
    "Then for any $\\epsilon > 0$ we have \n",
    "\n",
    "$ Pr[A_m > E[A_m] + \\epsilon] \\leq e^{-2m\\epsilon^2}$\n",
    "\n",
    "Speaking about risk miminization, we can ask a question, how well does $\\hat R$ approximates $R$?\n",
    "\n",
    "Given m random examples, and for any $\\delta > 0$, we can deduce that with probability $Pr >= 1 - \\delta$, the following upper bound holds on the generalization error of $h$:\n",
    "$R \\leq \\hat R + \\sqrt{ \\frac {\\ln(1 / \\delta)} {2m} }$\n",
    "\n",
    "For finite hypothesis space $H$ under the same conditions:\n",
    "$R \\leq \\hat R + \\sqrt{ \\frac {\\ln|H| + \\ln(1 / \\delta)} {2m} }$\n",
    "\n",
    "\n",
    "\n",
    "VC dimention is defined as the cardinality of the largest set of points that the algorithm can shatter.\n",
    "\n",
    "<img src=\"images/vc_dim.png\" style=\"height:300px\">\n",
    "\n",
    "Let H be a hypothesis space of VC-dimension $d \\le \\infty$, and assume that arandom training set of size $m$ is chosen where $m \\geq d \\geq 1$. Then for any $\\epsilon > 0$,\n",
    "\n",
    "$R \\leq \\hat R + \\sqrt{ \\frac {d\\ln(m / d) + \\ln(1 / \\delta)} {2m} }$\n",
    "\n",
    "Rademacher complexity:\n",
    "Suppose now that the labels $y_i$ are chosen at random without regard to the $x_i$. In other words, suppose we replace each $y_i$ by a random variable $\\sigma_i$ that is −1 or +1 with\n",
    "equal probability, independent of everything else. Thus, the $\\sigma_i$ represent labels that are pure noise. We can measure how well the space $H$ can fit this noise in expectation\n",
    "by  \n",
    "$E_{sigma} [\\max_{h \\in H} \\frac 1 m \\sum _{i=1}^m \\sigma_i h(x_i)]$, which is called Rademacher complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No free Lunch Theorem\n",
    "\n",
    "The No Free Lunch Theorems state that any one algorithm that searches for an optimal cost or fitness solution is not universally superior to any other algorithm.\n",
    "\n",
    "\"If an algorithm performs better than random search on some class of problems then in must perform worse than random search on the remaining problems.\" (No Free Lunch Theorems for Optimisation)\n",
    "\n",
    "How that affects machine learning?\n",
    "Every machine learning algorithm explicitly or implicitly implies some assumpsions made about observed data. So by contradicting these assumptions for every algorithm we create such dataset, where it achieves bad perfomance.\n",
    "\n",
    "<img src=\"images/lunch.png\" style=\"height:200px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias variance decomposition\n",
    "\n",
    "Suppose our data is generated by:  \n",
    "$y = f(x) + \\epsilon$, where $\\epsilon \\in N(0,\\sigma)$ is white noise.  \n",
    "We want to build such estimator, that:  \n",
    "$\\hat y = h(x)$ is our prediction  \n",
    "\n",
    "Consider MSE regression  \n",
    "\n",
    "$MSE = E[(y - h(x))^2] $  \n",
    "$ = E[(y - f(x) + f(x) - h(x))^2]$  \n",
    "$ = E[(y - f(x))^2] + E[(f(x) - h(x))^2] - 2E[(y - f(x)(f(x) - h(x))]$  \n",
    "$ = E[\\epsilon^2] + E[(f(x) - h(x))^2] - 2(E[yf(x)] - E[yh(x)] - E[f^2(x)] + E[f(x)h(x)] ) $  \n",
    "\n",
    "Notes:  \n",
    "$E[f^2(x)] = f^2(x)$ since f is deterministic  \n",
    "$E[yf(x)] = f^2(x)$ since $E[y] = f(x)$    \n",
    "$E[yh(x)] = E[f(x)h(x)] + E[\\epsilon h(x)] = E[f(x)h(x)] + 0$  \n",
    "\n",
    "\n",
    "$ = E[\\epsilon^2] + E[(f(x) - h(x))^2] - 2(f^2(x) - E[f(x)h(x)] + 0 - f^2(x) + E[f(x)h(x)]) $  \n",
    "$ = E[\\epsilon^2] + E[(f(x) - h(x))^2]$  \n",
    "$ = E[\\epsilon^2] + E[(f(x) - E[h(x)] + E[h(x)] -  h(x))^2]$  \n",
    "$ = E[\\epsilon^2] + E[(f(x) - E[h(x)])^2 ] + E[(E[h(x)] -  h(x))^2] + 2E[(E[h(x)] - h(x))(f(x) - E(h(x))]$  \n",
    "\n",
    "$ = E[\\epsilon^2] + E[(f(x) - E[h(x)])^2 ] + E[(E[h(x)] -  h(x))^2] + 2(E[f(x)E[h(x)]] -E[E[h(x)]^2]  - E[h(x)f(x)] + E[h(x)E[h(x)]])$  \n",
    "\n",
    "Notes:  \n",
    "$E[fE[h(x)]] = f(x)E[h(x)]$    \n",
    "$E[E[h(x)]^2] = E[h(x)]^2$  \n",
    "$E[f(x)h(x)] = f(x)E[h(x)]$    \n",
    "$E[h(x)E[h(x)]] = E[h(x)]^2$   \n",
    "\n",
    "$ = E[\\epsilon^2] + E[(f(x) - E[h(x)])^2 ] + E[(E[h(x)] -  h(x))^2] + 2(f(x)E[h(x)] -E[h(x)]^2  - f(x)E[h(x)] + E[h(x)]^2)$  \n",
    "\n",
    "$ = E[\\epsilon^2] + E[(f(x) - E[h(x)])^2 ] + E[(E[h(x)] -  h(x))^2]$  \n",
    "\n",
    "$ = Var[\\epsilon] + E[(f(x) - E[h(x)])^2 ] + Var[h(x)]$   \n",
    "$ = Var[\\epsilon] + bias^2 + Var[h(x)]$   \n",
    "\n",
    "Training and test error\n",
    "<img src=\"images/dec2.png\" style=\"height:400px\">\n",
    "\n",
    "Generalization error\n",
    "<img src=\"images/dec1.png\" style=\"height:400px\">\n",
    "\n",
    "## Learning curves\n",
    "\n",
    "High bias\n",
    "<img src=\"images/lc_bias.png\" style=\"height:400px\">\n",
    "\n",
    "High variance\n",
    "<img src=\"images/lc_var.png\" style=\"height:400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting and Regularization\n",
    "Overfitting is a situation, when a model fitted on a train dataset shows worse perfomance on a test dataset.  \n",
    "It corresponds to the fact, that model learns the given dataset but do not generalize to unseen data from the same distribution.  \n",
    "Every model does overfit!  \n",
    "\n",
    "<img src=\"images/overfitting.png\" style=\"height:300px\">\n",
    "\n",
    "\n",
    "In response to overfitting, there is regularization techniques.  \n",
    "In general, they correspond to setting restrictions onto hyposesis spaces, making generalization bound more tight. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality Metrics\n",
    "\n",
    "To effectively optimize our Loss functional by SGD it must be:\n",
    "1. differentialble almost everywhere\n",
    "2. represented as sum of losses on each object\n",
    "\n",
    "However, sometimes we may want to evaluate perfomance of our algorithm with some not so fancy measure. Here are some examples:\n",
    "* auc\n",
    "<img src=\"images/auc.png\" style=\"height:300px\">\n",
    "\n",
    "* f1 score\n",
    "<img src=\"images/f1.png\" style=\"height:300px\">\n",
    "\n",
    "<img src=\"images/f2.png\" style=\"height:200px\">\n",
    "\n",
    "In that case, we usually have 2 approaches:\n",
    "1. Create some differentiable approximation of quality metric\n",
    "1. Our use classic Loss functional, such that it's optimum coinsides with the optimum of your quality metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common model training pipeline\n",
    "\n",
    "1. Split dataset for train, test and validation parts\n",
    "1. train model on the train dataset without regularization, try to achive zero training loss\n",
    "1. add regularization, watch perfomance on the validation dataset\n",
    "1. test final model perfomance on test dataset. Choose between different model families.\n",
    "\n",
    "On the test dataset model must be evaluated by chosen quality metric, not by loss function used in model optimization.\n",
    "\n",
    "Regression\n",
    "<img src=\"images/pipeline.png\" style=\"height:600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation\n",
    "\n",
    "Given dataset for training our model, we usually mant to optimize its hyperparameters by measuring model perfomance on validation on different choices of hyperparameters. \n",
    "\n",
    "## 1 Leave One out\n",
    "Given dataset of m objects, create m experiments:  \n",
    "1. create split (m-1):1\n",
    "1. train on (m-1) object\n",
    "1. evaluate perfomance on the m-th object\n",
    "1. change split\n",
    "Average perfomance over all experiments\n",
    "\n",
    "Properties:\n",
    "1. High variance of estimate\n",
    "2. Low bias of estimate\n",
    "3. O(m) complexity\n",
    "4. Usually done when we have very small dataset\n",
    "\n",
    "Regression\n",
    "<img src=\"images/loo.png\" style=\"height:200px\">\n",
    "\n",
    "## 2 Hold out\n",
    "Given dataset of m objects, create m experiments:  \n",
    "1. create split train:val, usually in proportion 80:20\n",
    "1. train on train subset\n",
    "1. evaluate perfomance on the val subset\n",
    "\n",
    "Properties:\n",
    "1. Moderate variance of estimate\n",
    "1. High bias of estimate\n",
    "1. O(1) complexity\n",
    "1. Usually done when when we have large dataset and\\or very heavy model\n",
    "\n",
    "\n",
    "## 3 Cross validation\n",
    "k = number of folds  \n",
    "folds = non-intersecting subsets of the dataset  \n",
    "Given dataset of m objects, create k experiments:  \n",
    "1. create split for k-1:1\n",
    "1. train on (k-1) folds\n",
    "1. evaluate perfomance on the k-th\n",
    "1. change split\n",
    "Average perfomance over all experiments\n",
    "\n",
    "Properties:\n",
    "1. Low variance of estimate\n",
    "2. Moderate bias of estimate\n",
    "3. O(k) complexity\n",
    "4. Usually done with k=5 or k=10\n",
    "\n",
    "Regression\n",
    "<img src=\"images/cv.png\" style=\"height:600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal Bayesian classifier\n",
    "Suppose we have 2 classes.\n",
    "\n",
    "<img src=\"images/bayes.png\" style=\"height:400px\">\n",
    "\n",
    "Bayesian risk:\n",
    "$ R = \\sum_{x,y} I[h(x) \\neq y] P(x,y)c_y$, \n",
    "where $c_y$ is cost function for misclassification\n",
    "\n",
    "By applying Bayes rule:  \n",
    "$P(y |X) = \\frac {P(X|y) P(y) c_y} {P(X)}$\n",
    "\n",
    "$h(x) = \\arg \\max_y P(X | y) P(y) c_y$ is optimal Bayesian classifier\n",
    "\n",
    "\n",
    "We assign y = 1 iff:  \n",
    "$ P(X | y=1) P(y=1)c_1 > P(X | y=0) P(y=0)c_0 $  \n",
    "\n",
    "$ \\frac {P(X | y=1)}{P(X | y=0)} > \\frac {P(y=0)c_0} {P(y=1)c_1} $  \n",
    "\n",
    "Cost function and prior class probabilties are interchangable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
